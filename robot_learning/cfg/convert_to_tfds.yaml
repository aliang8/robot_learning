env_name: metaworld
task_name: mw-hammer
seed: 0
data_dir: ${paths.data_dir}/datasets/metaworld/tdmpc2_buffer_imgs
tfds_data_dir: ${paths.data_dir}/tensorflow_datasets
dataset_name: tdmpc2-buffer-imgs
precompute_embeddings: False 
black_white: False
batch_size: 64
framestack: 1

max_return: 1000
num_samples: 500
ckpt_num: 200000
save_imgs: False
debug: False

compute_2d_flow: False
flow:
  # TODO: fix the paths
  sam_path: ${paths.sam_path}
  sam2_checkpoint: checkpoints/sam2.1_hiera_large.pt
  model_cfg: sam2.1_hiera_l.yaml
  model_id: IDEA-Research/grounding-dino-tiny

  # `video_dir` a directory of JPEG frames with filenames like `<frame_index>.jpg`
  video_dir: notebooks/videos/robot
  video_file: data/videos/2024-09-21_13-26-56_raw_traj_group0_traj0.mp4

  # setup the input image and text prompt for SAM 2 and Grounding DINO
      # VERY important: text queries need to be lowercased + end with a dot
  text: "robot. objects." # TODO: this should change based on env
  device: cuda

  base_path: ${paths.optical_flow_path}
  cotracker_ckpt: scaled_offline.pth
  seg_mask_file: data/videos/segm_mask.npy
  grid_size: 25
  
  save_tracking_video: False
  tracking_dir: results
  tracking_filename: segm_grid
  max_query_points: 100

# Image embedding options
compute_embeddings: false
embedding_model: 'resnet50'  # Options: 'r3m', 'resnet50', 'radio-h', etc.
resnet_feature_map_layer: 'layer4'

defaults:
  - local: default
  - _self_